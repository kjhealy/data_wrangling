---
title: "Data Wrangling - 3. Manipulating tables with `dplyr`"
author: "Kieran Healy"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    lib_dir: "libs"
    chakra: "../libs/remark-latest.min.js"
    css: ["default", "../css/kjh-slides.css", "../css/kjh-inferno-fonts.css", "../css/animate.css"]
    seal: false
    anchor_sections: false
    nature:
      beforeInit: "../js/kjh-macros.js"
      highlightStyle: default
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
      navigation:
        scroll: false
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, 
                      fig.retina = 3, fig.align = "center")
```

```{r packages-data, include=FALSE}
library(flipbookr)
library(cowplot)
ggplot2::theme_set(theme_cowplot())

```

```{r xaringanExtra, echo=FALSE}
xaringanExtra::use_xaringan_extra(c("tile_view"))
xaringanExtra::use_animate_css()
xaringanExtra::use_animate_all("fade")
xaringanExtra::use_clipboard()
```

class: center middle main-title section-title-1

# Manipulating Tables with .kjh-yellow[dplyr]

.class-info[

**Session 3**

.light[Kieran Healy<br>
Statistical Horizons, April 2021]

]

---

layout: false
class: main-title main-title-inv

# .middle.squish4[Time to<br />play with<br />some .kjh-red[data]]

--

- woohoo!

---

layout: true
class: title title-1

---

# Load our libraries

.SMALL[
```{r 03-dplyr-basics-1, message = TRUE}
library(here)      # manage file paths
library(socviz)    # data and some useful functions
library(tidyverse) # your friend and mine
```
]

---

# Tidyverse components, again

.center[![:scale 100%](img/dplyr_1.png)]

---

# Tidyverse components, again

.center[![:scale 100%](img/dplyr_2.png)]

---

# Other tidyverse components

.center[![:scale 100%](img/dplyr_addnl_1.png)]

---

# Other tidyverse components

.center[![:scale 100%](img/dplyr_addnl_2.png)]


- Not all of these are attached when we do `library(tidyverse)`

---

# .kjh-yellow[dplyr] lets you work with tibbles

Remember, tibbles are tables of data where the columns can be of different types, such as numeric, logical, character, factor, etc.

--

We'll use dplyr to _transform_ and _summarize_ our data.

--

We'll use the pipe operator, **`%>%`**, to chain together sequences of actions on our tables.

--

---

layout: false
class: main-title main-title-inv

# .middle.squish4[`dplyr` draws on the logic and language of  .kjh-green[database queries], where the focus is on manipulating tables]

---

layout: true
class: title title-1

---

# Some .kjh-orange[actions] to take on a single table 

--

- **Group** the data at the level we want, such as “_Religion by Region_” or _“Children by School by District_”, so as to present data at that level.

--

- **Subset** either the rows or columns of or table.

--

- **Mutate**  the data. That is, change something at the _current_ level of grouping.  Mutating adds new columns to the table, or changes the content of an existing column. This won't change the number of rows.

--

- **Summarize** or aggregate the data. That is, make something new at a _higher_ level of grouping. E.g., calculate means or counts by some grouping variable. This will generally result in a smaller, _summary_ table.

---

# Each .kjh-orange[action] has a corresponding .kjh-green[function] 

--

- **Group** using  `group_by()`.

--

- **Subset** has one action for rows and one for columns. We `filter()` rows and `select()` columns. 

--

- **Mutate** tables (i.e. add new columns, or re-make existing ones) using `mutate()`.

--

- **Summarize** tables (i.e. perform aggregating calculations) using `summarize()`.

---

# General Social Survey data: .kjh-pink[`gss_sm`]

```{r 03-dplyr-basics-2}
## library(socviz) # if not loaded
gss_sm
```

--

Notice how the tibble already tells us a lot.

---

# Summarizing a Table

- Here's what we're going to do:

.center[![:scale 100%](img/dplyr-pipe-example.png)]

---

# Summarizing a table

```{r 03-dplyr-basics-3}
## Just take a look at the columns we will work on
gss_sm %>% 
  select(id, bigregion, religion)
```

We're just taking a look at the relevant columns here.

---

# Group by .kjh-orange[_one_] column or variable

```{r 03-dplyr-basics-4}

gss_sm %>% 
  group_by(bigregion)
```

Grouping just changes the logical structure of the tibble. 

---

`r chunk_reveal("03-dplyr-onecol-summary", widths = c(25,75), title = "# Group and summarize by .kjh-orange[_one_] column")`


```{r 03-dplyr-onecol-summary, include = FALSE}
gss_sm %>% 
  group_by(bigregion) %>% 
  summarize(total = n())
```

--

The function `n()` counts up the rows within each group.

--

All the other columns are dropped in the summary operation

--

Your original .kjh-pink[`gss_sm`] table is untouched

---

`r chunk_reveal("03-dplyr-twocol-summary", widths = c(25,75), title = "# Group and summarize by .kjh-orange[_two_] columns")`


```{r 03-dplyr-twocol-summary, include = FALSE}
gss_sm %>% 
  group_by(bigregion, religion) %>% 
  summarize(total = n())
```

--

The function `n()` counts up the rows within the _innermost_ (i.e. the rightmost) group.

---

`r chunk_reveal("03-dplyr-freq", widths = c(30,70), title = "# Calculate frequencies")`


```{r 03-dplyr-freq, include = FALSE}
gss_sm %>% 
  group_by(bigregion, religion) %>% 
  summarize(total = n()) %>% 
  mutate(freq = total / sum(total),
           pct = round((freq*100), 1))
```

--

The function `n()` counts up the rows 

--

Which rows? The ones fed down the pipeline

--

The _innermost_ (i.e. the rightmost) group.

---

# Pipelines carry some assumptions forward

.small[
```{r 03-dplyr-basics-5}
gss_sm %>% 
  group_by(bigregion, religion) %>% #<<
  summarize(total = n()) %>% 
  mutate(freq = total / sum(total),
           pct = round((freq*100), 1))
```
]

Groups are carried forward till summarized or explicitly ungrouped

--

Summary calculations are done on the innermost group, which then "disappears". (Notice how it's no longer a group in the output.)

---

# Pipelines carry some assumptions forward

.small[
```{r 03-dplyr-basics-6}
gss_sm %>% 
  group_by(bigregion, religion) %>% 
  summarize(total = n()) %>% 
  mutate(freq = total / sum(total),
           pct = round((freq*100), 1)) #<<
```
]

`mutate()` is very clever. See how we can immediately use `freq`, even though we are creating it in the same `mutate()` expression.

---

# Convenience functions

.small[

```{r 03-dplyr-basics-7}
gss_sm %>% 
  group_by(bigregion, religion) %>% #<<
  summarize(total = n()) %>% #<<
  mutate(freq = total / sum(total),
           pct = round((freq*100), 1)) 
```
]

We're going to be doing this `group_by()` ... `n()` step a lot. Some shorthand for it would be useful.

---

# Three options for counting up rows

.pull-left-3[

- .SMALL.squish3[Do it yourself]

.SMALL[
```{r 03-dplyr-basics-8}
gss_sm %>% 
  group_by(bigregion, religion) %>% #<<
  summarize(n = n()) #<<
```
]

- .small.squish3[Result is a grouped tibble]
]

--

.pull-middle-3[

- .SMALL.squish3[use `tally()`]

.SMALL[
```{r 03-dplyr-basics-9}
gss_sm %>% 
  group_by(bigregion, religion) %>% 
  tally() #<<
```
]

- .small.squish3[Group it yourself; output is grouped]
]

--

.pull-right-3[

- .SMALL.squish3[use `count()`]

.SMALL[
```{r 03-dplyr-basics-10}
gss_sm %>% 
  count(bigregion, religion) #<<
```
]

- .small.squish3[One step; result is not grouped]
]

---

# Pass your pipeline on to ... a .kjh-yellow[table]

```{r 03-dplyr-basics-11, eval = FALSE}
gss_sm %>% 
  count(bigregion, religion) %>% 
  pivot_wider(names_from = bigregion, values_from = n) %>%  #<<
  kable()  
```


.small[
```{r 03-dplyr-basics-12, echo = FALSE}
gss_sm %>% 
  count(bigregion, religion) %>% 
  pivot_wider(names_from = bigregion, values_from = n) %>% 
  kable()  
```
]

More on `pivot_wider()` and `kable()` soon ...

---

# Pass your pipeline on to ... a .kjh-yellow[graph]

```{r 03-dplyr-basics-13, echo = FALSE}
theme_set(cowplot::theme_cowplot())
```

.SMALL[
```{r 03-dplyr-basics-14, fig.height=4, fig.width=15}
gss_sm %>% 
  group_by(bigregion, religion) %>% 
  tally() %>% 
  mutate(pct = round((n/sum(n))*100), 1) %>% 
  drop_na() %>% 
  ggplot(mapping = aes(x = pct, y = reorder(religion, -pct), fill = religion)) + 
  geom_col() +
    labs(x = "Percent", y = NULL) +
    guides(fill = FALSE) + 
    facet_wrap(~ bigregion, nrow = 1)
```
]

---

# Pass your pipeline on to ... an .kjh-yellow[object]

.pull-left[
- .SMALL.squish3[You can do it like this ...]
```{r 03-dplyr-basics-15}
rel_by_region <- gss_sm %>% #<<
  count(bigregion, religion) %>% 
  mutate(pct = round((n/sum(n))*100, 1)) 

rel_by_region
```
]

--

.pull-right[

- .SMALL.squish3[Or like this!]
```{r 03-dplyr-basics-16}
gss_sm %>% 
  count(bigregion, religion) %>% 
  mutate(pct = round((n/sum(n))*100, 1)) -> #<<
rel_by_region #<<

rel_by_region
```

]

---

# .kjh-lblue[Right] assignmment is a thing, just like .kjh-red[Left]

.pull-left[

- .kjh-red[Left] assignment is standard

```{r 03-dplyr-basics-17}
gss_tab <- gss_sm %>% 
  count(bigregion, religion) 
```

.left[This may feel awkward with a pipe: "`gss_tab` .kjh-orange[_gets_] the output of the following pipeline."]

]

--

.pull-right[

- .kjh-lblue[Right] assignment also works!

```{r 03-dplyr-basics-18}
gss_sm %>% 
  count(bigregion, religion) -> gss_tab  
  
```

.right[Without any authority, I assert that right-assignment should be read as, e.g., "This pipeline .kjh-orange[_begets_] `gss_tab`"]

]
---

# Pipelined tables can be quickly checked

.pull-left[

```{r 03-dplyr-basics-19}
rel_by_region <- gss_sm %>% 
  count(bigregion, religion) %>% 
  mutate(pct = round((n/sum(n))*100, 1)) 

rel_by_region
```

Hm, did I sum over right group?

]

--
.pull-right[

```{r 03-dplyr-basics-20}
## Each region should sum to ~100
rel_by_region %>% 
  group_by(bigregion) %>% 
  summarize(total = sum(pct)) 

```

No! What has gone wrong here?

]

---

# Pipelined tables can be quickly checked

.pull-left[

```{r 03-dplyr-basics-21}
rel_by_region <- gss_sm %>% 
  count(bigregion, religion) %>% #<< 
  mutate(pct = round((n/sum(n))*100, 1)) 
```

.SMALL.squish3[`count()` returns ungrouped results, so no groups carry forward to the `mutate()` step.]

```{r 03-dplyr-basics-22}
rel_by_region %>% 
  summarize(total = sum(pct))
```

.SMALL.squish3[With `count()`, the `pct` values here are the marginals for the whole table.]

]

--
.pull-right[

```{r 03-dplyr-basics-23}
rel_by_region <- gss_sm %>% 
  group_by(bigregion, religion) %>% #<<
  tally() %>% #<<
  mutate(pct = round((n/sum(n))*100, 1)) 
```

```{r 03-dplyr-basics-24}
# Check
rel_by_region %>% 
  group_by(bigregion) %>% 
  summarize(total = sum(pct))

```

.SMALL.squish3[We get some rounding error because we used `round()` after summing originally.]
]


---

# Two lessons

## Check your tables!

-     Pipelines feed their content forward, so you need to make sure your results are not incorrect.

--

- Often, complex tables and graphs can be disturbingly plausible even when wrong.

--

- So, figure out what the result should be and test it!

--

- Starting with simple or toy cases can help with this process.

---

# Two lessons

## Inspect your pipes!

- Understand pipelines by running them forward or peeling them back a step at a time.

- This is a _very_ effective way to understand your own and other people's code.

---

# Following a pipeline

```{r 03-dplyr-basics-25, echo = FALSE}
theme_set(cowplot::theme_minimal_grid())
```


```{r 03-dplyr-basics-26, fig.height = 4, fig.width=10 }
gss_sm %>% 
  group_by(race, sex, degree) %>% 
  summarize(n = n(), 
            mean_age = mean(age, na.rm = TRUE), 
            mean_kids = mean(childs, na.rm = TRUE)) %>% 
  mutate(pct = n/sum(n)*100) %>% 
  filter(race !="Other") %>% 
  drop_na() %>% 
  ggplot(mapping = aes(x = mean_kids, y = degree)) + # I'm sorry I can't talk more about the graphs
  geom_col() + facet_grid(sex ~ race) + 
  labs(x = "Average number of Chidren", y = NULL)
```

---

`r chunk_reveal("03-kid-pipeline", widths = c(40,60), title = "# Following a pipeline")`


```{r 03-kid-pipeline, include = FALSE} 
gss_sm %>% 
  group_by(race, sex, degree) %>% 
  summarize(n = n(), 
            mean_age = mean(age, na.rm = TRUE), 
            mean_kids = mean(childs, na.rm = TRUE)) %>% 
  mutate(pct = n/sum(n)*100) %>% 
  filter(race !="Other") %>% 
  drop_na() %>% 
  summarize(grp_totpct = sum(pct))
```

---

# Conditionals in .kjh-yellow[`select()`] and .kjh-yellow[`filter()`]

Some new data, this time on national rates of cadaveric organ donation:

```{r 03-dplyr-basics-27}
# library(socviz)
organdata
```

---

# Conditionals in .kjh-yellow[`select()`] and .kjh-yellow[`filter()`]

```{r 03-dplyr-basics-28}
organdata %>% 
  filter(consent_law == "Informed" & donors > 15) 
```

---

# Conditionals in .kjh-yellow[`select()`] and .kjh-yellow[`filter()`]

```{r 03-dplyr-basics-29}
organdata %>% 
  select(country, year, where(is.integer)) #<<
```

Use `where()` to test columns.

---

# Conditionals in .kjh-yellow[`select()`] and .kjh-yellow[`filter()`]

When telling `where()` use `is.integer()` to test each column, we don't put parentheses at the end of its name. If we did, R would try to evaluate `is.integer()` right then, and fail:

```r
> organdata %>% 
+   select(country, year, where(is.integer()))
Error: 0 arguments passed to 'is.integer' which requires 1
Run `rlang::last_error()` to see where the error occurred.
```

This is true in similar situations elsewhere as well.

---

# Conditionals in .kjh-yellow[`select()`] and .kjh-yellow[`filter()`]

```{r 03-dplyr-basics-30}
organdata %>% 
  select(country, year, where(is.character))
```

We have functions like e.g. `is.character()`, `is.numeric()`, `is.logical()`, `is.factor()`, etc. All return either .kjh-green[`TRUE`] or .kjh-red[`FALSE`]. 

---

# Conditionals in .kjh-yellow[`select()`] and .kjh-yellow[`filter()`]

Sometimes we don't pass a function, but do want to use the result of one:

```{r 03-dplyr-basics-31}
organdata %>% 
  select(country, year, starts_with("gdp")) #<<
```

We have `starts_with()`, `ends_with()`, `contains()`, `matches()`, and `num_range()`. Collectively these are "tidy selectors".

---

# Conditionals in .kjh-yellow[`select()`] and .kjh-yellow[`filter()`]

```{r 03-dplyr-basics-32}
organdata %>% 
  filter(country == "Australia" | country == "Canada") 
```

This could get cumbersome fast.

---

# Use .kjh-yellow[`%in%`] for multiple selections

```{r 03-dplyr-basics-33}
my_countries <- c("Australia", "Canada", "United States", "Ireland")

organdata %>% 
  filter(country %in% my_countries) #<<
```

---

# Negating .kjh-yellow[`%in%`] 

```{r 03-dplyr-basics-34}
my_countries <- c("Australia", "Canada", "United States", "Ireland")

organdata %>% 
  filter(!(country %in% my_countries)) #<<
```

Also a bit awkward. There's no built-in "Not in" operator. 


---

# Negating .kjh-yellow[`%in%`] 

We can make one!

```{r 03-dplyr-basics-35}
`%nin%` <- Negate(`%in%`) # this operator is included in the socviz package
```

.small.squish3[(The backticks are special here because we need to name an operator.)]

--
.SMALL[
```{r 03-dplyr-basics-36}
organdata %>% 
  filter(country %nin% my_countries) #<<
```
]


---

# Doing more than one thing 

Earlier we saw this:

```{r 03-dplyr-basics-37}
gss_sm %>% 
  group_by(race, sex, degree) %>% 
  summarize(n = n(), 
            mean_age = mean(age, na.rm = TRUE), 
            mean_kids = mean(childs, na.rm = TRUE))
```

---

# Doing more than one thing 

.SMALL.squish3[Similarly for `organdata` we might want to do:]

.small[

```{r 03-dplyr-basics-38}
organdata %>%  
  group_by(consent_law, country) %>%
  summarize(donors_mean = mean(donors, na.rm = TRUE),
            donors_sd = sd(donors, na.rm = TRUE),
            gdp_mean = mean(gdp, na.rm = TRUE),
            health_mean = mean(health, na.rm = TRUE),
            roads_mean = mean(roads, na.rm = TRUE))
```

]

This works, but it's really tedious. Also error-prone.

---

# Doing more than one thing with .kjh-yellow[`across()`]

.SMALL.squish3[Instead, use `across()` to apply a function to more than one column.]

.SMALL[
```{r 03-across-pipeline-1}

my_vars <- c("gdp", "donors", "roads")

## nested parens again, but it's worth it
organdata %>% 
  group_by(consent_law, country) %>%
  summarize(across(my_vars,           
                   list(avg = mean),  
                   na.rm = TRUE))     
```
]

---

`r chunk_reveal("03-across-pipeline-1", widths = c(40,60), title = "# Let's look at that again")`

- .small.squish3[`my_vars` are selected by `across()`]

--

- .small.squish3[`list()` of the form `result = function` gives the new columns that will be calculated.]

--

- .small.squish3[`na.rm = TRUE` is passed through to the functions inside the `list()`]

---

# We can calculate more than one thing

.small[
```{r 03-dplyr-basics-40}

my_vars <- c("gdp", "donors", "roads")

organdata %>% 
  group_by(consent_law, country) %>%
  summarize(across(my_vars,           
                   list(avg = mean, #<<
                        sd = var, #<<
                        md = median),#<<  
                   na.rm = TRUE))     
```
]


---

# It's OK to use the function names 

.small[
```{r 03-dplyr-basics-41}

my_vars <- c("gdp", "donors", "roads")

organdata %>% 
  group_by(consent_law, country) %>%
  summarize(across(my_vars,           
                   list(mean = mean, #<<
                        var = var, #<<
                        median = median),#<<  
                   na.rm = TRUE))     
```
]

---

# Conditionally select with .kjh-yellow[`across(where())`]

.SMALL[

```{r 03-dplyr-basics-42}
organdata %>% 
  group_by(consent_law, country) %>%
  summarize(across(where(is.numeric), #<<       
                   list(mean = mean, 
                        var = var, 
                        median = median),
                   na.rm = TRUE)) %>% 
    print(n = 3) # just to save slide space
```
]


---

# Name new columns with .kjh-yellow[`.names`]

.pull-left[

.SMALL[
```{r 03-dplyr-basics-43}
organdata %>% 
  group_by(consent_law, country) %>%
  summarize(across(where(is.numeric),        
                   list(mean = mean, 
                        var = var, 
                        median = median),
                   na.rm = TRUE, 
                   .names = "{fn}_{col}")) %>% #<<
  print(n = 3) 
```
]
]

.pull-right[

.small.squish3[In tidyverse functions, arguments that begin with a "`.`" generally have it in order to avoid confusion with existing items, or are "pronouns" referring to e.g. "the name of the thing we're currently talking about as we evaluate this function". ]

]

---

# This all works with .kjh-yellow[`mutate()`], too


```{r 03-dplyr-basics-44}
organdata %>% 
  mutate(across(where(is.character), toupper)) %>% 
  select(where(is.character))
```

---

# Arrange rows and columns

Sort rows with `arrange()`

.pull-left[

```{r 03-dplyr-basics-45}
organdata %>% 
  group_by(consent_law, country) %>%
  summarize(donors = mean(donors, na.rm = TRUE)) %>% 
  arrange(donors) %>% ##< 
  print(n = 5)
```

]

.pull-right[

```{r 03-dplyr-basics-46}
organdata %>% 
  group_by(consent_law, country) %>%
  summarize(donors = mean(donors, na.rm = TRUE)) %>% 
  arrange(desc(donors)) %>%  ##<
  print(n = 5)
```

]

Using `arrange()` to order rows in this way won't respect groupings.

---

# More generally ...

```{r 03-dplyr-basics-47}
organdata %>% 
  group_by(consent_law, country) %>%
  summarize(donors = mean(donors, na.rm = TRUE)) %>% 
  slice_max(donors, n = 5) #<<
```

.small.squish3[You can see that `slice_max()` respects grouping.]

.small.squish3[There's `slice_min()`, `.slice_head()`, `slice_tail()`, `slice_sample()`, and the most general one, `slice()`.] 

---

# `dplyr`'s .kjh-yellow[window] functions 

Ranking and cumulation within groups.  


```{r 03-dplyr-basics-48}
## Data on COVID-19
library(covdata)

covnat_weekly 
```

---

# `dplyr`'s .kjh-yellow[window] functions 

 `cumsum()` gives cumulative sums

```{r 03-dplyr-basics-49}
covnat_weekly %>% 
  filter(cname == "United States") %>% 
  select(date, cname, iso3, cases) %>% 
  mutate(cumulative = cumsum(cases)) 

```

---

# `dplyr`'s .kjh-yellow[window] functions 

.SMALL[`cume_dist()` gives the proportion of values less than or equal to the current value.]

```{r 03-dplyr-basics-50}
covnat_weekly %>% 
  select(date, cname, iso3, deaths) %>% 
  filter(cname == "United States") %>% 
  filter(cume_dist(desc(deaths)) < 0.1) # i.e. Top 10%

```

.SMALL.squish3[The `dplyr` vignette on Window functions is good.] 

---

# An application 

```{r 03-dplyr-basics-51}
covus %>% 
  filter(measure == "death") %>% 
  group_by(state) %>% 
  arrange(state, desc(date)) %>% 
  filter(state %in% "NY")
```

.SMALL.squish3[Here the `count` measure is _cumulative_ deaths. What if we want to recover the daily count for all the states in the data?]

---

# An application 

`dplyr` has `lead()` and `lag()` functions. These allow you to access the previous and next values in a vector. You can calculate offsets this way.

```{r 03-dplyr-basics-52}
my_vec <- c(1:20)
my_vec
lag(my_vec) # first element has no lag

my_vec - lag(my_vec)

```

---

# An application

.SMALL.squish3[We can write the expression directly:]

.SMALL[
```{r 03-dplyr-basics-53}
covus %>%
  select(-data_quality_grade) %>% 
  filter(measure == "death") %>%
  group_by(state) %>%
  arrange(date) %>% 
  mutate(deaths_daily = count - lag(count, order_by = date)) %>% 
  arrange(state, desc(date)) %>% 
  filter(state %in% "NY")
  
```
]
---

# Writing our own .kjh-orange[functions]

But we could also write a function to do this. 

We write functions using the special `function()` function.\*

.SMALL[

```{r 03-dplyr-basics-54}
my_fun <- function(x) {
  x + 1
}

my_fun # we've created the function; it's just an object

my_fun(x = 1) # But we can supply it with an input!

my_fun(10)
```

]

.smaller[.footnote[.kjh-darkgrey[\*Nerds love this sort of stuff.]]]

---

# Writing our own .kjh-orange[functions]

We write our function. It's just the expression we originally wrote, wrapped up.

```{r 03-dplyr-basics-55}
get_daily_count <- function(count, date){
  count - lag(count, order_by = date)
}
```

This function has no generality, error-handling, or anything else. It's a once-off.

---

# Writing our own .kjh-orange[functions]

.SMALL.squish3[Now we can use it like any other:]

.SMALL[
```{r 03-dplyr-basics-56}
covus %>%
  filter(measure == "death") %>%
  select(-data_quality_grade) %>% 
  group_by(state) %>%
  arrange(date) %>% 
  mutate(deaths_daily = get_daily_count(count, date)) %>% 
  arrange(state, desc(date)) %>% 
  filter(state %in% "NY")
  
```
]

.SMALL.squish3[Not super-useful quite yet, but if our task had more steps ...]

---

# Tidy moving averages with .kjh-orange[`slider`]  

`dplyr`'s window functions don't include moving averages. 

There are several options, notably [`RcppRoll`](https://cran.r-project.org/web/packages/RcppRoll/index.html)

We'll use the .kjh-orange[[`slider`](https://cran.r-project.org/web/packages/slider/vignettes/slider.html)] package.

```{r 03-dplyr-basics-57}
# install.packages("slider")
library(slider)
```

---

# Tidy moving averages with .kjh-orange[`slider`]  

.SMALL[

```{r 03-dplyr-basics-58}
covus %>%
  filter(measure == "death") %>%
  select(-data_quality_grade) %>% 
  group_by(state) %>%
  arrange(date) %>% 
  mutate(
    deaths_daily = get_daily_count(count, date), 
    deaths7 = slide_mean(deaths_daily, #<<
                         before = 7, #<<
                         na_rm = TRUE)) %>% #<<
  arrange(state, desc(date)) %>% 
  filter(state %in% "NY")
```

]
---

# Tidy moving averages with .kjh-orange[`slider`]  

```r
    deaths7 = slide_mean(deaths_daily, #<<
                         before = 7, #<<
                         na_rm = TRUE)) %>% #<<
```

.SMALL[

Notice the Tidyverse-style `na_rm` argument rather than the usual base `na.rm`

The package provides a lot of different functions, from general-purpose `slide_max()`, `slide_min()` to more specialized sliding functions. In particular note e.g. `slide_index_mean()` that addresses some subtleties in averaging over dates with gaps. 
]

---

# Tidying up after yourself with .kjh-yellow[`relocate()`]

```{r 03-dplyr-basics-59}
gss_sm
```

---

```{r 03-relocate-pipeline, include = FALSE}
gss_sm %>% 
  select(region, bigregion, year, 
         id:region, 
         starts_with("p"), 
         contains("income")) %>% 
  rename(children = childs, 
         siblings = sibs) %>% 
  relocate(id) %>% 
  select(-ballot) %>% 
  relocate(where(is.numeric), 
           .before = where(is.factor)) %>% 
  relocate(contains("region"), 
           .after = year) 
```

`r chunk_reveal("03-relocate-pipeline", widths = c(35,65), title = "# Shuffle columns around")`


---

layout: false
class: main-title main-title-inv

# .middle.squish4.large[Two dplyr .kjh-red[gotchas]]

---

layout: true
class: title title-1

---

# Comparisons filtering on proportions

Let's say you are working with proportions

```{r, echo = FALSE}

# Make some sample data with tribb
df <- tribble(~id, ~ prop1, ~prop2,
              "A", 0.1,      0.2,
              "B", 0.1,      0.21, 
              "C", 0.11,     0.2,
              "D", 0.1,      0.1)
```

```{r}
df
```

---

# Comparisons filtering on proportions

And you want to focus on cases where `prop1` _plus_ `prop2` is greater than 0.3:

--

```{r}
df %>% 
  filter(prop1 + prop2 > 0.3)
```

`A` shouldn't have been included there.

--

This is not dlpyr's fault. It's our floating point friend again.

---

# Comparisons filtering on proportions


```{r}
df %>% 
  filter(prop1 + prop2 == 0.3)
```

`A` _should_ have been included here!

---

# Comparisons filtering on proportions

This won't give the right behavior either:

```{r}
df %>% 
  mutate(prop3 = prop1 + prop2) %>% 
  filter(prop3 == 0.3)
```

---

# Comparisons filtering on proportions

So, beware.

```{r}
df %>% 
  filter(prop1*100 + prop2*100 == 0.3*100)
```

Better:

```{r}
df %>% 
  filter(near(prop1 + prop2, 0.3))
```

---

# .kjh-orange[Zero Counts] in dplyr

```{r}
df <- read_csv(here("data", "first_terms.csv"))

df
```

---

#  .kjh-orange[Zero Counts] in dplyr

```{r, echo = FALSE}
## Hex colors for sex
sex_colors <- c("#E69F00", "#993300")

## Group labels
mf_labs <- tibble(M = "Men", F = "Women")

theme_set(cowplot::theme_cowplot())

```


```{r}
df %>%
    group_by(start_year, party, sex) %>%
    summarize(N = n()) %>%
    mutate(freq = N / sum(N))

```

---

#  .kjh-orange[Zero Counts] in dplyr


```{r}
p_col <- df %>%
    group_by(start_year, party, sex) %>%
    summarize(N = n()) %>%
    mutate(freq = N / sum(N)) %>%
    ggplot(aes(x = start_year,
               y = freq,
               fill = sex)) +
    geom_col() +
    scale_y_continuous(labels = scales::percent) +
    scale_fill_manual(values = sex_colors, labels = c("Women", "Men")) +
    labs(x = "Year", y = "Percent", fill = "Group") +
    facet_wrap(~ party)
```

---

#  .kjh-orange[Zero Counts] in dplyr

```{r, fig.height = 6, fig.width=8}
p_col
```

---

#  .kjh-orange[Zero Counts] in dplyr

```{r}
p_line <- df %>%
    group_by(start_year, party, sex) %>%
    summarize(N = n()) %>%
    mutate(freq = N / sum(N)) %>%
    ggplot(aes(x = start_year,
               y = freq,
               color = sex)) +
    geom_line(size = 1.1) +
    scale_y_continuous(labels = scales::percent) +
    scale_color_manual(values = sex_colors, labels = c("Women", "Men")) +
    guides(color = guide_legend(reverse = TRUE)) +
    labs(x = "Year", y = "Percent", color = "Group") +
    facet_wrap(~ party)
```

---

#  .kjh-orange[Zero Counts] in dplyr

```{r, fig.height = 6, fig.width=9}
p_line
```

---

# Option 1: the `.drop` Flag

```{r}
df %>%
    group_by(start_year, party, sex, 
             .drop = FALSE) %>%
    tally()
```

---

# Option 1: the `.drop` Flag

You can check this 

```{r}
group_by_drop_default(df)
```

---

# Option 2: .kjh-yellow[ungroup()] .kjh-green[and complete()]

```{r}
df_c <- df %>%
    group_by(start_year, party, sex) %>%
    summarize(N = n()) %>%
    mutate(freq = N / sum(N)) %>%
    ungroup() %>%#<<
    complete(start_year, party, sex,#<<
             fill = list(N = 0, freq = 0))#<<
```

---

# Option 2: .kjh-yellow[ungroup()] .kjh-green[and complete()]


```{r}
df_c
```

---

# Option 2: .kjh-yellow[ungroup()] .kjh-green[and complete()]

```{r}
p_out <- df_c %>% 
  ggplot(aes(x = start_year,
               y = freq,
               color = sex)) +
    geom_line(size = 1.1) +
    scale_y_continuous(labels = scales::percent) +
    scale_color_manual(values = sex_colors, labels = c("Women", "Men")) +
    guides(color = guide_legend(reverse = TRUE)) +
    labs(x = "Year", y = "Percent", color = "Group") +
    facet_wrap(~ party)
```

---

# Option 2: .kjh-yellow[ungroup()] .kjh-green[and complete()]

```{r, fig.height = 6, fig.width=9}
p_out
```

