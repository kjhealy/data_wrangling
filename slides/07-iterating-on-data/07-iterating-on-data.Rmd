---
title: "Data Wrangling - 7. .kjh-green[Iterating] on data"
author: "Kieran Healy"
date: "`r Sys.Date()`"
output:
  xaringan::moon_reader:
    lib_dir: "libs"
    chakra: "../libs/remark-latest.min.js"
    css: ["default", "../css/kjh-slides.css", "../css/kjh-inferno-fonts.css", "../css/animate.css"]
    seal: false
    anchor_sections: false
    nature:
      beforeInit: "../js/kjh-macros.js"
      highlightStyle: default
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
      navigation:
        scroll: false
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE, 
                      fig.retina = 3, fig.align = "center")
```

```{r packages-data, include=FALSE}
library(flipbookr)
library(cowplot)
ggplot2::theme_set(theme_cowplot())

```

```{r xaringanExtra, echo=FALSE}
xaringanExtra::use_xaringan_extra(c("tile_view"))
xaringanExtra::use_animate_css()
xaringanExtra::use_animate_all("fade")
xaringanExtra::use_clipboard()
```

class: center middle main-title section-title-1

# .kjh-green[Iterating] on data with .kjh-yellow[purrr] and .kjh-yellow[map]  

.class-info[

**Session 7**

.light[Kieran Healy<br>
Statistical Horizons, April 2021]

]

---

layout: true
class: title title-1

---

# Load the packages, as always

.SMALL[
```{r 06-getting-data-in-1, message = TRUE}
library(here)      # manage file paths
library(socviz)    # data and some useful functions
library(tidyverse) # your friend and mine
```
]

---

layout: false
class: main-title main-title-inv

# .middle.squish4.huge[.kjh-orange[Moar Data]]

---

layout: true
class: title title-1

---

# More than one data file

.SMALL[Inside the `data/` folder of the course packet is a folder named `congress/`]


.smaller[

```{r}
# A little trick from the fs package: 
fs::dir_tree(here("data", "congress"))
```

]

---

# More than one data file

.SMALL[Let's look at one.]

```{r}
read_csv(here("data", "congress", "17_95_congress.csv")) %>% 
  janitor::clean_names() %>% 
  head()
```

We often find ourselves in this situation. We know each file has the same structure, and we would like to use them all at once. 

---

# Loops?

How to read them all in?

One traditional way, which we could do in R, is to write an explicit _loop_ that iterated over a vector of filenames, read each file, and then joined the results together in a tall rectangle.

```r
# Pseudocode

filenames <- c("01_79_congress.csv", "02_80_congress.csv", "03_81_congress.csv",
                "04_82_congress.csv" [etc etc])

collected_files <- NULL

for(i in 1:length(filenames)) {
      new_file <- read_file(filenames[i])
      collected_files <- append_to(collected_files, new_files)
}


```

---

# Loops?

You may have noticed we have not written any loops, however.

While loops are still lurking there underneath the surface, what we will do instead is to take advantage of the combination of vectors and functions and _map_ one to the other in order to generate results.

Speaking loosely, think of `map()` as a way of .kjh-green[Iterating] without writing loops. You start with a vector of things and you feed it to the function one thing at a time. The function does whatever it does, and you get back output that is the same length as your input.

---

# Mapping is just a kind of iteration

The `purrr` package provides a big family of mapping functions. One reason there are a lot of them is that `purrr`, like the rest of the tidyverse, is picky about data types. 

--

So in addition to the basic `map()`, which always returns a _list_, we also have `map_chr()`, `map_int()`, `map_dbl()`, `map_lgl()` and others. They always return the data type indicated by their suffix, or die trying.

---

# Vectorized arithmetic again

The simplest cases are not that different from the vectorized arithmetic we're already familiar with. 

```{r}
a <- c(1:10)

b <- 1

# You know what R will do here
a + b

```

--

R's vectorized rules add `b` to every element of `a`. In a sense, the **`+`** operation can be thought of as a function that takes each element of `a` and does something with it. In this case "add `b`".  

---

# Vectorized arithmetic again

We can make this explicit by writing a function:

```{r}
add_b <- function(x) {
  b <- 1
  x + b # for any x
}
```

Now:

```{r}
add_b(x = a)
```

---

# Vectorized arithmetic again


Again, R's vectorized approach means it automatically adds `b` to every element of the x we give it.

```{r}
add_b(x = 10)
```

```{r}
add_b(x = c(1, 99, 1000))
```

---

# .kjh-green[Iterating] in a pipeline
Some operations can't directly be vectorized in this way, which is why we need to manually iterate, or will want to write loops. 

```{r}
library(gapminder)
gapminder %>% 
  summarize(n_distinct(country), 
            n_distinct(continent), 
            n_distinct(year), 
            n_distinct(lifeExp), 
            n_distinct(population))
```

That's tedious to write. Computers are supposed to allow us to avoid that sort of thing.

---

# .kjh-green[Iterating] in a pipeline

So how would we iterate this? What we want is to apply the `n_distinct()` function to each column of `gapminder`, but in a way that still allows us to use pipelines and so on. 

```{r}
library(gapminder)
gapminder %>% 
  summarize(n_distinct(country), 
            n_distinct(continent), 
            n_distinct(year), 
            n_distinct(lifeExp), 
            n_distinct(population))
```

.smaller.kjh-darkgrey[Using `n_distinct()` in this context is an idea I got from Rebecca Barter's discussion of `purrr`.]

---

# .kjh-green[Iterating] in a pipeline

You'd use _across()_, of course.

```{r}
gapminder %>% 
  summarize(across(everything(), n_distinct))
```

---

# .kjh-green[Iterating] in a pipeline

But you could also do this ... 

.pull-left[

.SMALL[

```{r}
  map(gapminder, n_distinct)
```
]

]

.pull-right[
Read it as "Feed each column of `gapminder` to the `n_distinct()` function.
]

.footnote[(This is pretty much what `across()` is doing more nicely.)]

---

# .kjh-green[Iterating] in a pipeline

.pull-left[

.SMALL[

Or, in pipeline form:

```{r}
gapminder %>% 
  map(n_distinct)
```

]
]

.pull-right[

You can see we are getting a _list_ back.

]

---

# .kjh-green[Iterating] in a pipeline

Or, in pipeline form:

```{r}
result <- gapminder %>% 
  map(n_distinct)

class(result)

result$continent

result[[2]]
```


---

# .kjh-green[Iterating] in a pipeline

In this context, `n_distinct()` is always going to return an integer, though.


```{r}
gapminder %>% 
  map_int(n_distinct)
```

The thing about the `map()` family is that they can deal with all kinds of input types and output types.

---

# Get a vector of .kjh-pink[filenames]

```{r}
filenames <- dir(path = here("data", "congress"),
                 pattern = "*.csv",
                 full.names = TRUE)

filenames[1:15] # Just displaying the first 15, to save slide space

```

---

# And feed it to .kjh-yellow[read_csv()]

```{r}
df <- filenames %>% 
  map_dfr(read_csv, .id = "congress") %>% #<<
  janitor::clean_names()

df
```

.SMALL.squish3[... using the variant of `map()` that returns data frames and tibbles.]

---

layout: false
class: main-title main-title-inv

.top[![:scale 100%](img/emperor-witness.png)]

---

layout: true
class: title title-1

---

# Cleaning up .kjh-yellow[congress]

```{r}
df %>% 
  select(born, death, start, end)
```

We'll use the **lubridate** package to sort these out. 

Lubridate has a wide range of functions to handle dates, times, and durations. 

???

In particular it has many convenience functions to help with the many different ways that people encode dates that _ought_ to be encoded as `YYYY-MM-DD`.

---

# Cleaning up .kjh-yellow[congress]

```{r}
library(lubridate)

date_recodes <- c("born", "death", "start", "end")

df <- df %>% 
    mutate(across(any_of(date_recodes), mdy), 
           congress = as.double(congress) + 78)

df 

```

---

# Cleaning up .kjh-yellow[congress]

```{r}
sessions <- tibble(congress = 79:116,
                   start_year = seq(1945, 2019, by = 2),
                   end_year = seq(1947, 2021, by = 2)) %>% 
  mutate(start_year = ymd(paste(start_year, "01", "03", sep = "-")), 
         end_year = ymd(paste(end_year, "01", "03", sep = "-")))


sessions

```

---

# We're going to join these tables


.pull-left[

The big table

.SMALL[

```{r}
df %>% 
  select(congress, last, born)

```
]

]

.pull-right[

The smaller table

.SMALL[

```{r}
sessions

```

]
]

---

# We're going to .kjh-orange[join] these tables

.SMALL.squish3[We will use **`left_join()`** which is what you want most of the time when you are looking to merge a smaller table with additional information into a larger main one. ]

.SMALL[

```{r, message = TRUE}

df <- left_join(df, sessions) %>% 
  relocate(start_year:end_year, .after = congress)  

df 

```

]

---

# Table joins

.footnote[*Spiffy Join Animatations courtesy [Garrick Aden-Buie](github.com/gadenbuie/join-animations-with-gganimate.R)]

.top[![:scale 40%](img/original-dfs.png)]

---

# Left join, .kjh-yellow[left_join()]

.top[![:scale 40%](img/left-join.gif)]

.SMALL[All rows from x, and all columns from x and y. Rows in x with no match in y will have NA values in the new columns.]

---

# Left join (contd), .kjh-yellow[left_join()]

.top[![:scale 40%](img/left-join-extra.gif)]

.SMALL[If there are multiple matches between x and y, all combinations of the matches are returned.]

---

# Inner join, .kjh-yellow[inner_join()]


.top[![:scale 40%](img/inner-join.gif)]

.SMALL[All rows from x where there are matching values in y, and all columns from x and y.]
---

# Full join, .kjh-yellow[full_join()]

.top[![:scale 40%](img/full-join.gif)]

.SMALL[All rows and all columns from both x and y. Where there are not matching values, returns NA for the one missing.]
---

# Semi join, .kjh-yellow[semi_join()]

.top[![:scale 40%](img/semi-join.gif)]

.SMALL[All rows from x where there are matching values in y, keeping just columns from x.]
---

# Anti join, .kjh-yellow[anti_join()]

.top[![:scale 40%](img/anti-join.gif)]

.SMALL[All rows from x where there are not matching values in y, keeping just columns from x.]
---

# Left join, .kjh-yellow[left_join()]

Most of the time you will be looking to make a **`left_join()`**

---

layout: false
class: main-title main-title-inv

# .middle.squish4.huge[.kjh-red[Missing Data]]

---

layout: true
class: title title-1

---

# A quick plug for .kjh-yellow[naniar] and .kjh-yellow[visdat]

```{r}
library(naniar)
library(visdat)

organdata
```

```{r, fig.height=6, fig.width=8}
gg_miss_var(organdata)
```

---

# A quick plug for .kjh-yellow[naniar] and .kjh-yellow[visdat]

```{r, fig.height=6, fig.width=8}
vis_dat(organdata)
```

---

# A quick plug for .kjh-yellow[naniar] and .kjh-yellow[visdat]

```{r, fig.height=6, fig.width=8}
miss_var_summary(organdata)
```


---

# A quick plug for .kjh-yellow[naniar] and .kjh-yellow[visdat]

```{r}
miss_case_summary(organdata)
```

---

# A quick plug for .kjh-yellow[naniar] and .kjh-yellow[visdat]

```{r}
organdata %>%
  select(consent_law, year, pubhealth, roads) %>%
  group_by(consent_law) %>%
  miss_var_summary()

```

---

# A quick plug for .kjh-yellow[naniar] and .kjh-yellow[visdat]

```{r, fig.height=6, fig.width=8}
vis_miss(organdata)
```

---

# A quick plug for .kjh-yellow[naniar] and .kjh-yellow[visdat]

```{r, fig.height=6, fig.width=8}
library(congress)
gg_miss_upset(congress)
```

---

# A quick plug for .kjh-yellow[naniar] and .kjh-yellow[visdat]

```{r, fig.height=6, fig.width=8}
vis_miss(organdata, cluster = TRUE)
```

---

# A quick plug for .kjh-yellow[naniar] and .kjh-yellow[visdat]

```{r, fig.height=6, fig.width=8}
gg_miss_upset(organdata)
```

---

# .kjh-yellow[Upset plots] and a bit of wrangling

![:scale 35%](img/covid-symptoms-venn.jpg)

---

# .kjh-yellow[Upset plots] and a bit of wrangling

```{r}
symptoms <- c("Anosmia", "Cough", "Fatigue", 
              "Diarrhea", "Breath", "Fever")
names(symptoms) <- symptoms
symptoms
```

---

# .kjh-yellow[Upset plots] and a bit of wrangling

.SMALL[

```{r}
# An Excel file!
dat <- readxl::read_xlsx(here("data", "symptoms.xlsx")) 
dat %>% print(n = nrow(dat))

```

]

---

# .kjh-yellow[Upset plots] and a bit of wrangling

.SMALL[

```{r}
subsets <- dat %>% 
  pull(combination)

## Check if each subset mentions each symptom or not
symptom_mat <- map_dfc(subsets, str_detect, symptoms) %>%
    data.frame() %>%
    t() %>% # transpose the result, this is a little gross, sorry
    as_tibble(.name_repair = "unique")

colnames(symptom_mat) <- symptoms
symptom_mat$count <- dat$count
```

]

---

# .kjh-yellow[Upset plots] and a bit of wrangling

Now we have a table we can do something with.

.SMALL[


```{r}
symptom_mat %>% print(n = nrow(symptom_mat))
```

]
---

# .kjh-yellow[Upset plots] and a bit of wrangling

Uncounting tables

.SMALL[

```{r}
indvs <- symptom_mat %>%
    uncount(count) 

indvs

```

]

Now we've reconstructed the individual-level observations.

---

# .kjh-yellow[Upset plots] and a bit of wrangling


```{r, fig.width=16, fig.height=9, eval = FALSE}
# devtools::install_github("krassowski/complex-upset")

library(ComplexUpset)

upset(data = indvs, intersect = symptoms, 
      name="Symptom Groupings by Frequency. Total pool is 1,764 individuals.", 
      min_size = 0,
      width_ratio = 0.125) +
    labs(title = "Co-Occurence of COVID-19 Symptoms",
         caption = "Data: covid.joinzoe.com/us | Graph: @kjhealy")


```

---

# .kjh-yellow[Upset plots] and a bit of wrangling


```{r, fig.width=12, fig.height=7, echo = FALSE}
# devtools::install_github("krassowski/complex-upset")

library(ComplexUpset)

upset(data = indvs, intersect = symptoms, 
      name="Symptom Groupings by Frequency. Total pool is 1,764 individuals.", 
      min_size = 0,
      width_ratio = 0.125) +
    labs(title = "Co-Occurence of COVID-19 Symptoms",
         caption = "Data: covid.joinzoe.com/us | Graph: @kjhealy")


```

---

layout: false
class: main-title main-title-inv

# .middle.squish4.huge[.kjh-green[Models]]

---

layout: true
class: title title-1

---

# This is not a .kjh-yellow[statistics] seminar!

I'll just give you an example of the sort of thing that many other modeling packages implement for all kinds of modeling techniques.

Again, the principle is tidy incorporation of models and their output.

---

# Tidy regression output with .kjh-yellow[broom]

```{r}
library(broom)
library(gapminder)
```


```{r 07-.kjh-green[Iterating]-2}
out <- lm(formula = lifeExp ~ gdpPercap + pop + continent,
          data = gapminder)
```

---

# Tidy regression output with .kjh-yellow[broom]

We can't _do_ anything with this, programatically.

.SMALL[

```{r 07-.kjh-green[Iterating]-3}
summary(out)
```

]
---

# Tidy regression output with .kjh-yellow[broom]

```{r 07-.kjh-green[Iterating]-8}
library(broom)
```

```{r 07-.kjh-green[Iterating]-9}
tidy(out)
```

That's a _lot_ nicer. Now it's just a tibble. We know those.

---

# Tidy regression output with .kjh-yellow[broom]

.SMALL[

```{r 07-.kjh-green[Iterating]-11}
out_conf <- tidy(out, conf.int = TRUE)
out_conf 
```

]

---

# Tidy regression output with .kjh-yellow[broom]

.SMALL[

```{r}
out_conf %>%
    filter(term %nin% "(Intercept)") %>%
    mutate(nicelabs = prefix_strip(term, "continent")) %>%
    select(nicelabs, everything())
```

]

---

# Grouped analysis and .kjh-orange[list columns]

```{r 07-.kjh-green[Iterating]-20}
eu77 <- gapminder %>% filter(continent == "Europe", year == 1977)
fit <- lm(lifeExp ~ log(gdpPercap), data = eu77)
```

.SMALL[

```{r 07-.kjh-green[Iterating]-21}

summary(fit)
```

]

---

# Grouped analysis and .kjh-orange[list columns]

```{r 07-.kjh-green[Iterating]-22}

out_le <- gapminder %>%
    group_by(continent, year) %>%
    nest()

out_le

```

Think of nesting as a kind of "super-grouping". Look in the object inspector.

---

# Grouped analysis and .kjh-orange[list columns]

It's still in there.

```{r 07-.kjh-green[Iterating]-23}
out_le %>% filter(continent == "Europe" & year == 1977) %>% 
    unnest(cols = c(data))
```

---

# Grouped analysis and .kjh-orange[list columns]

```{r 07-.kjh-green[Iterating]-24, echo = FALSE}
old_digits <- getOption("digits")
options(digits = 3)
```

Here we `map()` a custom function to every row in the `data` column.

```{r 07-.kjh-green[Iterating]-25}

fit_ols <- function(df) {
    lm(lifeExp ~ log(gdpPercap), data = df)
}

out_le <- gapminder %>%
    group_by(continent, year) %>%
    nest() %>% 
    mutate(model = map(data, fit_ols)) #<<
```

---

# Grouped analysis and .kjh-orange[list columns]


```{r}
out_le
```


---

# Grouped analysis and .kjh-orange[list columns]

We can tidy the nested models, too.

```{r 07-.kjh-green[Iterating]-26}

fit_ols <- function(df) {
    lm(lifeExp ~ log(gdpPercap), data = df)
}

out_tidy <- gapminder %>%
    group_by(continent, year) %>%
    nest() %>% 
    mutate(model = map(data, fit_ols),
           tidied = map(model, tidy)) %>%
    unnest(cols = c(tidied)) %>%
    filter(term %nin% "(Intercept)" &
           continent %nin% "Oceania")
```


---

# Grouped analysis and .kjh-orange[list columns]

```{r}
out_tidy
```

---

# Grouped analysis and .kjh-orange[list columns]

```{r}
out_tidy %>% 
    ungroup() %>%
    sample_n(5)
```


```{r 07-.kjh-green[Iterating]-27, echo = FALSE}
options(digits = old_digits)
```

